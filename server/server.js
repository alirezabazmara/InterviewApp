require("dotenv").config();
const express = require("express");
const multer = require("multer");
const pdfParse = require("pdf-parse");
const cors = require("cors");
const fs = require("fs");
const path = require("path");
const { OpenAI } = require("openai");
const { spawn } = require("child_process");

const app = express(); 
const corsOptions = {
  origin: [
    'https://interview-app-tan.vercel.app',
    'https://interview-app-83467631s-projects.vercel.app',
    'http://localhost:5000' 
  ],
  methods: ['GET', 'POST', 'PUT', 'DELETE', 'OPTIONS'],
  allowedHeaders: ['Content-Type', 'Authorization'],
  credentials: true
};

app.use(cors(corsOptions));
app.use(express.json());


app.get("/", (req, res) => {
  res.send("ğŸ‰ Backend is running and ready!");
});


const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
const RESPONSE_FILE = "responses.json";

// Ø§ÛŒØ¬Ø§Ø¯ `response.json` Ø¯Ø± ØµÙˆØ±Øª Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯
if (!fs.existsSync(RESPONSE_FILE)) {
  fs.writeFileSync(RESPONSE_FILE, JSON.stringify([]));
}

const upload = multer({ dest: "uploads/" });

// Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ÛŒÚ© Map Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø³ÙˆØ§Ù„Ø§Øª Ù‚Ø¨Ù„ÛŒ
const previousQuestions = new Map();

// ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ multer
const storage = multer.diskStorage({
  destination: function (req, file, cb) {
    // Ø§ÛŒØ¬Ø§Ø¯ ÛŒÚ© Ø¯Ø§ÛŒØ±Ú©ØªÙˆØ±ÛŒ Ù…ÙˆÙ‚Øª
    const tempDir = path.join(__dirname, 'temp');
    if (!fs.existsSync(tempDir)) {
      fs.mkdirSync(tempDir);
    }
    cb(null, tempDir);
  },
  filename: function (req, file, cb) {
    // Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² timestamp Ø¨Ø±Ø§ÛŒ Ù†Ø§Ù… ÙØ§ÛŒÙ„
    cb(null, `temp_${Date.now()}.webm`);
  }
});

const audioUpload = multer({ 
  storage: storage,
  fileFilter: (req, file, cb) => {
    if (file.mimetype === "audio/webm" || file.mimetype === "audio/webm;codecs=opus") {
      cb(null, true);
    } else {
      cb(new Error("Invalid file type. Only webm audio is allowed."), false);
    }
  }
});

// âœ… **Ø¢Ù¾Ù„ÙˆØ¯ Ø±Ø²ÙˆÙ…Ù‡ Ùˆ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ØªÙ†**
app.post("/upload-resume", upload.single("resume"), async (req, res) => {
  console.log("âœ… Received Resume Upload Request");

  if (!req.file) {
    console.error("âŒ No file uploaded.");
    return res.status(400).json({ success: false, message: "No file uploaded." });
  }

  try {
    const pdfData = await pdfParse(fs.readFileSync(req.file.path));
    console.log("âœ… Processing Resume...");

    // Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø±Ø²ÙˆÙ…Ù‡ Ø¨Ø§ GPT
    const featuresResponse = await openai.chat.completions.create({
      model: "gpt-4-turbo",
      messages: [
        {
          role: "system",
          content: `Extract key features from the resume and return them in the following JSON format:
          {
            "skills": ["skill1", "skill2", ...],
            "experience": [
              {
                "title": "job title",
                "duration": "duration",
                "technologies": ["tech1", "tech2", ...]
              }
            ],
            "education": ["education1", "education2", ...],
            "certifications": ["cert1", "cert2", ...]
          }`
        },
        {
          role: "user",
          content: pdfData.text
        }
      ],
      response_format: { type: "json_object" }
    });

    const features = JSON.parse(featuresResponse.choices[0].message.content);
    console.log("âœ… Extracted Features:", features);

    return res.json({ 
      success: true, 
      text: pdfData.text,
      features: features
    });
  } catch (error) {
    console.error("âŒ Error processing PDF:", error);
    return res.status(500).json({ success: false, message: "Error processing PDF" });
  }
});

// âœ… **ØªÙˆÙ„ÛŒØ¯ Ø³ÙˆØ§Ù„Ø§Øª Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…ØªÙ† Ø±Ø²ÙˆÙ…Ù‡**
app.post("/generate-questions", async (req, res) => {
  const { text } = req.body;

  if (!text) {
    return res.status(400).json({ success: false, message: "No resume text provided." });
  }

  try {
    console.log("âœ… Generating questions based on resume...");

    const questionsResponse = await openai.chat.completions.create({
      model: "gpt-4-turbo",
      messages: [
        { role: "system", content: "Generate 5 specific and technical interview questions based on the following resume text. Questions should start from the easiest." },
        { role: "user", content: text },
      ],
      max_tokens: 200,
    });

    console.log("ğŸ”¹ OpenAI Raw Response:", questionsResponse);

    const questions = questionsResponse.choices[0].message.content
      .split("\n")
      .map(q => q.replace(/^\d+\.\s*/, "").trim())
      .filter(q => q.length > 0 && q.includes("?"));

    if (!questions || questions.length === 0) {
      console.error("âŒ No questions generated.");
      return res.status(500).json({ success: false, message: "No questions generated." });
    }

    console.log("âœ… Generated Questions:", questions);
    return res.json({ success: true, questions });
  } catch (error) {
    console.error("âŒ Error generating questions:", error);
    return res.status(500).json({ success: false, message: "Error generating questions" });
  }
});

// âœ… **Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ùˆ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ù…ØªÙ†**
app.post("/save-audio", audioUpload.single("audio"), async (req, res) => {
  if (!req.file) {
    console.error("âŒ No audio file uploaded");
    return res.status(400).json({ success: false, message: "No audio file uploaded." });
  }

  try {
    console.log("âœ… Processing audio file:", req.file.path);
    
    // ØªØ¨Ø¯ÛŒÙ„ ØµØ¯Ø§ Ø¨Ù‡ Ù…ØªÙ†
    const transcription = await openai.audio.transcriptions.create({
      file: fs.createReadStream(req.file.path),
      model: "whisper-1",
      language: "en",
    });

    console.log("âœ… Transcription completed:", transcription.text);

    // Ø­Ø°Ù ÙØ§ÛŒÙ„ Ù…ÙˆÙ‚Øª Ø¨Ø¹Ø¯ Ø§Ø² ØªØ¨Ø¯ÛŒÙ„
    fs.unlink(req.file.path, (err) => {
      if (err) {
        console.error("âŒ Error deleting temp file:", err);
      } else {
        console.log("âœ… Temp file deleted successfully");
      }
    });

    if (!transcription.text) {
      console.error("âŒ No text extracted from audio");
      return res.status(400).json({ 
        success: false, 
        message: "No text could be extracted from the audio" 
      });
    }

    try {
      // ØªØ­Ù„ÛŒÙ„ Ù¾Ø§Ø³Ø® Ø¨Ø§ OpenAI
      const analysisPrompt = `
      Question: "${req.body.question}"
      Answer: "${transcription.text}"

      Analyze the answer based on the following criteria:
      1. Relevance to the question
      2. Technical accuracy
      3. Depth of knowledge
      4. Practical experience demonstration
      5. Communication clarity

      Return the analysis in this exact JSON format:
      {
        "score": <number between 0 and 1>,
        "explanation": "<detailed explanation>",
        "strengths": ["<point 1>", "<point 2>", ...],
        "weaknesses": ["<point 1>", "<point 2>", ...],
        "suggestion": "<suggestion for improvement>"
      }`;

      console.log("âœ… Sending analysis request to OpenAI");
      
      const completion = await openai.chat.completions.create({
        model: "gpt-4-turbo",
        messages: [
          {
            role: "system",
            content: "You are an expert technical interviewer. Analyze interview answers objectively and provide detailed feedback."
          },
          {
            role: "user",
            content: analysisPrompt
          }
        ],
        response_format: { type: "json_object" }
      });

      console.log("âœ… Received analysis from OpenAI");
      
      const analysis = JSON.parse(completion.choices[0].message.content);

      // ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ù…ØªÛŒØ§Ø²
      let decision;
      if (analysis.score >= 0.9) {
        decision = "Next question from resume";
      } else if (analysis.score >= 0.7) {
        decision = "Answer was good but could be more detailed";
      } else if (analysis.score >= 0.5) {
        decision = "Ask a simpler question in the same topic";
      } else {
        decision = "Change topic after two consecutive weak answers";
      }

      // Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± responses.json
      let responses = [];
      if (fs.existsSync(RESPONSE_FILE)) {
        responses = JSON.parse(fs.readFileSync(RESPONSE_FILE));
      }

      const responseData = {
        question: {
          text: req.body.question,
          category: 'basic'
        },
        answer: transcription.text,
        score: analysis.score,
        explanation: analysis.explanation,
        strengths: analysis.strengths,
        weaknesses: analysis.weaknesses,
        suggestion: analysis.suggestion,
        decision,
        timestamp: new Date().toISOString()
      };

      responses.push(responseData);
      fs.writeFileSync(RESPONSE_FILE, JSON.stringify(responses, null, 2));

      console.log("âœ… Response saved successfully");

      res.json({ 
        success: true, 
        text: transcription.text,
        analysis: responseData
      });

    } catch (analysisError) {
      console.error("âŒ Error analyzing response:", analysisError);
      res.status(500).json({ 
        success: false, 
        message: "Error analyzing response",
        text: transcription.text 
      });
    }

  } catch (error) {
    console.error("âŒ Error processing audio:", error);
    // Ø­Ø°Ù ÙØ§ÛŒÙ„ Ù…ÙˆÙ‚Øª Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§
    if (req.file && req.file.path) {
      fs.unlink(req.file.path, () => {});
    }
    res.status(500).json({ 
      success: false, 
      message: "Error processing audio",
      error: error.message 
    });
  }
});

// ØªØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ¨Ø¯ÛŒÙ„ Ù…ØªÙ† Ø¨Ù‡ ØµØ¯Ø§
async function generateSpeech(text) {
  try {
    const mp3 = await openai.audio.speech.create({
      model: "tts-1", // ÛŒØ§ "tts-1-hd" Ø¨Ø±Ø§ÛŒ Ú©ÛŒÙÛŒØª Ø¨Ø§Ù„Ø§ØªØ±
      voice: "alloy", // Ù…ÛŒâ€ŒØªÙˆÙ†Ù‡ "echo", "fable", "onyx", "nova", ÛŒØ§ "shimmer" Ù‡Ù… Ø¨Ø§Ø´Ù‡
      input: text,
    });

    // ØªØ¨Ø¯ÛŒÙ„ response Ø¨Ù‡ Buffer
    const buffer = Buffer.from(await mp3.arrayBuffer());
    
    // Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø¨Ø§ Ù†Ø§Ù… ÛŒÙˆÙ†ÛŒÚ©
    const fileName = `speech_${Date.now()}.mp3`;
    const filePath = path.join(__dirname, 'public', 'audio', fileName);
    
    // Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² ÙˆØ¬ÙˆØ¯ Ø¯Ø§ÛŒØ±Ú©ØªÙˆØ±ÛŒ
    if (!fs.existsSync(path.join(__dirname, 'public', 'audio'))) {
      fs.mkdirSync(path.join(__dirname, 'public', 'audio'), { recursive: true });
    }
    
    fs.writeFileSync(filePath, buffer);
    
    return `/audio/${fileName}`; // Ù…Ø³ÛŒØ± Ù†Ø³Ø¨ÛŒ Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªØ±Ø³ÛŒ Ø§Ø² Ø·Ø±ÛŒÙ‚ URL
  } catch (error) {
    console.error('âŒ Error generating speech:', error);
    throw error;
  }
}

// Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† middleware Ø¨Ø±Ø§ÛŒ Ø³Ø±Ùˆ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ§ØªÛŒÚ©
app.use('/audio', express.static(path.join(__dirname, 'public', 'audio')));

// Ù…Ø·Ù…Ø¦Ù† Ø´ÙˆÛŒØ¯ Ú©Ù‡ Ø¯Ø§ÛŒØ±Ú©ØªÙˆØ±ÛŒ audio ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯
const audioDir = path.join(__dirname, 'public', 'audio');
if (!fs.existsSync(audioDir)) {
  fs.mkdirSync(audioDir, { recursive: true });
}

// ØªØºÛŒÛŒØ± endpoint ØªÙˆÙ„ÛŒØ¯ Ø³ÙˆØ§Ù„Ø§Øª Ø¨Ø±Ø§ÛŒ Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ØµØ¯Ø§
app.post('/generate-basic-questions', async (req, res) => {
  try {
    const { topic } = req.body;
    
    if (!topic) {
      return res.status(400).json({
        success: false,
        message: "Topic field is required"
      });
    }

    // Ø¯Ø±ÛŒØ§ÙØª Ø³ÙˆØ§Ù„Ø§Øª Ù‚Ø¨Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† topic
    const existingQuestions = previousQuestions.get(topic) || [];

    const prompt = `Generate 10 simple and basic interview questions about ${topic}.
    Requirements:
    - Questions should be very basic and straightforward
    - Focus on fundamental concepts
    - Make questions short and easy to understand
    - No complex scenarios or advanced topics
    - Avoid any questions similar to these previous questions: ${JSON.stringify(existingQuestions)}
    - Each question should be unique and different from others
    - Questions should cover different aspects of the topic
    
    Return the response in this exact format:
    {
      "questions": [
        {
          "text": "Question text here",
          "difficulty": "basic",
          "category": "basic"
        }
      ]
    }`;

    const completion = await openai.chat.completions.create({
      messages: [{ 
        role: "system", 
        content: "You are an interviewer. Generate unique and simple questions that are easy to understand and answer. Avoid repetition." 
      }, { 
        role: "user", 
        content: prompt 
      }],
      model: "gpt-4-turbo",
      max_tokens: 1000,
    });

    const response = JSON.parse(completion.choices[0].message.content);
    
    if (!response.questions || response.questions.length === 0) {
      throw new Error("No questions generated");
    }

    // ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† Ø³ÙˆØ§Ù„Ø§Øª ØªÚ©Ø±Ø§Ø±ÛŒ
    const uniqueQuestions = filterDuplicateQuestions(response.questions, existingQuestions);

    // Ø§Ú¯Ø± ØªØ¹Ø¯Ø§Ø¯ Ø³ÙˆØ§Ù„Ø§Øª Ù…Ù†Ø­ØµØ± Ø¨Ù‡ ÙØ±Ø¯ Ú©Ù…ØªØ± Ø§Ø² 10 Ø¨ÙˆØ¯ØŒ Ø³ÙˆØ§Ù„Ø§Øª Ø¬Ø¯ÛŒØ¯ ØªÙˆÙ„ÛŒØ¯ Ú©Ù†
    if (uniqueQuestions.length < 10) {
      const additionalQuestions = await generateAdditionalQuestions(
        topic,
        uniqueQuestions,
        existingQuestions
      );
      uniqueQuestions.push(...additionalQuestions);
    }

    // Ø°Ø®ÛŒØ±Ù‡ Ø³ÙˆØ§Ù„Ø§Øª Ø¬Ø¯ÛŒØ¯ Ø¯Ø± Ø­Ø§ÙØ¸Ù‡
    const updatedQuestions = [...existingQuestions, ...uniqueQuestions];
    previousQuestions.set(topic, updatedQuestions);

    console.log(`âœ… Generated ${uniqueQuestions.length} unique basic questions for topic: ${topic}`);

    // Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ØµØ¯Ø§ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø³ÙˆØ§Ù„
    const questionsWithAudio = await Promise.all(
      uniqueQuestions.slice(0, 10).map(async (question) => {
        try {
          const audioPath = await generateSpeech(question.text);
          return {
            ...question,
            audioUrl: audioPath
          };
        } catch (error) {
          console.error(`âŒ Error generating audio for question: ${question.text}`, error);
          return question;
        }
      })
    );

    res.json({
      success: true,
      questions: questionsWithAudio,
      topic: topic
    });
  } catch (error) {
    console.error('âŒ Error:', error);
    res.status(500).json({
      success: false,
      message: 'Failed to generate questions'
    });
  }
});

// ØªØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ Ø¨Ø±Ø§ÛŒ ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† Ø³ÙˆØ§Ù„Ø§Øª ØªÚ©Ø±Ø§Ø±ÛŒ
function filterDuplicateQuestions(newQuestions, existingQuestions) {
  const uniqueQuestions = [];
  const seenTexts = new Set(existingQuestions.map(q => q.text.toLowerCase()));

  for (const question of newQuestions) {
    const normalizedText = question.text.toLowerCase();
    if (!seenTexts.has(normalizedText)) {
      uniqueQuestions.push(question);
      seenTexts.add(normalizedText);
    }
  }

  return uniqueQuestions;
}

// ØªØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ø³ÙˆØ§Ù„Ø§Øª Ø§Ø¶Ø§ÙÛŒ
async function generateAdditionalQuestions(topic, currentQuestions, existingQuestions) {
  const neededCount = 10 - currentQuestions.length;
  
  const prompt = `Generate ${neededCount} more unique and simple interview questions about ${topic}.
  Requirements:
  - Questions must be completely different from these existing questions: ${JSON.stringify([...currentQuestions, ...existingQuestions])}
  - Keep questions basic and straightforward
  - Focus on different aspects of the topic
  
  Return the response in this exact format:
  {
    "questions": [
      {
        "text": "Question text here",
        "difficulty": "basic",
        "category": "basic"
      }
    ]
  }`;

  const completion = await openai.chat.completions.create({
    messages: [{ 
      role: "system", 
      content: "Generate additional unique questions, avoiding any repetition with existing questions." 
    }, { 
      role: "user", 
      content: prompt 
    }],
    model: "gpt-4-turbo",
    max_tokens: 500,
  });

  const response = JSON.parse(completion.choices[0].message.content);
  return filterDuplicateQuestions(response.questions, [...currentQuestions, ...existingQuestions]);
}

// endpoint Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡ Ø¨Ø±Ø§ÛŒ ØªØ¨Ø¯ÛŒÙ„ Ù…ØªÙ† Ø¨Ù‡ ØµØ¯Ø§
app.post('/text-to-speech', async (req, res) => {
  try {
    const { text } = req.body;
    
    if (!text) {
      return res.status(400).json({
        success: false,
        message: "Text is required"
      });
    }

    const audioPath = await generateSpeech(text);

    res.json({
      success: true,
      audioUrl: audioPath
    });
  } catch (error) {
    console.error('âŒ Error generating speech:', error);
    res.status(500).json({
      success: false,
      message: 'Failed to generate speech'
    });
  }
});

// endpoint Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ù†ØªØ§ÛŒØ¬
app.get('/get-results', (req, res) => {
  try {
    if (fs.existsSync(RESPONSE_FILE)) {
      const results = JSON.parse(fs.readFileSync(RESPONSE_FILE));
      res.json({
        success: true,
        results
      });
    } else {
      res.json({
        success: false,
        message: 'No results found'
      });
    }
  } catch (error) {
    console.error('Error reading results:', error);
    res.status(500).json({
      success: false,
      message: 'Error reading results'
    });
  }
});

// Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† endpoint Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† responses
app.post('/clear-responses', (req, res) => {
  try {
    // Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ù…Ø­ØªÙˆØ§ÛŒ ÙØ§ÛŒÙ„ Ø¨Ø§ Ø¢Ø±Ø§ÛŒÙ‡ Ø®Ø§Ù„ÛŒ
    fs.writeFileSync(RESPONSE_FILE, JSON.stringify([]));
    
    console.log("âœ… Responses cleared successfully");
    res.json({ 
      success: true, 
      message: "Responses cleared" 
    });
  } catch (error) {
    console.error("âŒ Error clearing responses:", error);
    res.status(500).json({ 
      success: false, 
      message: "Error clearing responses" 
    });
  }
});

// endpoint Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª responses
app.get('/check-responses', (req, res) => {
  try {
    const responses = JSON.parse(fs.readFileSync(RESPONSE_FILE));
    res.json({
      success: true,
      count: responses.length,
      lastResponse: responses[responses.length - 1] || null
    });
  } catch (error) {
    res.status(500).json({
      success: false,
      message: "Error reading responses",
      error: error.message
    });
  }
});

app.post("/generate-resume-questions", async (req, res) => {
  const { features, topic } = req.body;

  if (!features || !topic) {
    return res.status(400).json({ 
      success: false, 
      message: "Features and topic are required" 
    });
  }

  try {
    // Ø³Ø§Ø®Øª Ù…ØªÙ† Ø±Ø²ÙˆÙ…Ù‡ Ø§Ø² ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§
    const resumeText = `
      Skills: ${features.skills.join(', ')}
      Experience: ${features.experience.map(exp => 
        `${exp.title} (${exp.duration}): ${exp.technologies.join(', ')}`
      ).join('\n')}
    `;

    const prompt = `Based on the following resume features and topic, generate exactly 7 technical interview questions. 
    The questions should be specific to the candidate's skills mentioned in the resume.
    Format each question as a JSON object with 'text' and 'type' fields.
    Each questions should be concise
    The type should be 'technical'.

    Resume features:
    ${resumeText}`;

    const completion = await openai.chat.completions.create({
      model: "gpt-3.5-turbo",
      messages: [
        {
          role: "system",
          content: "You are an expert technical interviewer. Generate exactly 7 specific, relevant interview questions based on the candidate's resume skills. Return the questions as a JSON array."
        },
        {
          role: "user",
          content: prompt
        }
      ],
      temperature: 0.7,
      max_tokens: 1000
    });

    // ØªØ¨Ø¯ÛŒÙ„ Ù¾Ø§Ø³Ø® Ø¨Ù‡ Ø¢Ø±Ø§ÛŒÙ‡ JSON
    const questions = completion.choices[0].message.content
      .split('\n')
      .filter(q => q.trim().length > 0 && q.includes('?'))
      .map(q => ({
        text: q.replace(/^\d+\.\s*/, '').trim().replace(/^"text":\s*"/, '').replace(/"$/, ''), 
        type: 'technical',
        category: 'resume-based'
      }));

    // Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ØµØ¯Ø§ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø³ÙˆØ§Ù„
    const questionsWithAudio = await Promise.all(
      questions.map(async (question) => {
        try {
          const audioPath = await generateSpeech(question.text);
          return {
            ...question,
            audioUrl: audioPath
          };
        } catch (error) {
          console.error(`Error generating audio for question: ${question.text}`, error);
          return question;
        }
      })
    );

    res.json({ 
      success: true, 
      questions: questionsWithAudio 
    });
  } catch (error) {
    console.error("Error generating resume questions:", error);
    res.status(500).json({ 
      success: false, 
      message: "Error generating resume questions" 
    });
  }
});

// Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† endpoint Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ø±Ø²ÙˆÙ…Ù‡
app.post("/calculate-resume-score", async (req, res) => {
  const { features, topic } = req.body;

  if (!features || !topic) {
    return res.status(400).json({ 
      success: false, 
      message: "Features and topic are required" 
    });
  }

  try {
    // Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ø¨Ø± Ø§Ø³Ø§Ø³ ÙØ±Ù…ÙˆÙ„
    let totalScore = 0;
    let scoreBreakdown = {
      experience: 0,
      skills: 0,
      projects: 0,
      complexity: 0
    };

    // ØªØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø³Ø§Ù„â€ŒÙ‡Ø§ÛŒ ØªØ¬Ø±Ø¨Ù‡
    const calculateExperienceYears = (experience) => {
      let totalYears = 0;
      
      // ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† ØªØ¬Ø±Ø¨Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø· Ø¨Ø§ topic
      const relevantExperience = experience.filter(exp => {
        const titleLower = exp.title.toLowerCase();
        const technologiesLower = exp.technologies.map(tech => tech.toLowerCase());
        const topicLower = topic.toLowerCase();

        // Ø¨Ø±Ø±Ø³ÛŒ Ø¹Ù†ÙˆØ§Ù† Ø´ØºÙ„
        if (titleLower.includes(topicLower) || topicLower.includes(titleLower)) {
          return true;
        }

        // Ø¨Ø±Ø±Ø³ÛŒ ØªÚ©Ù†ÙˆÙ„ÙˆÚ˜ÛŒâ€ŒÙ‡Ø§
        const hasRelevantTech = technologiesLower.some(tech => 
          tech.includes(topicLower) || topicLower.includes(tech)
        );

        // Ø¨Ø±Ø±Ø³ÛŒ Ø§Ø±ØªØ¨Ø§Ø· Ø¯Ø± Ø¹Ù†ÙˆØ§Ù† Ø´ØºÙ„
        const titleWords = titleLower.split(/\s+/);
        const hasRelevantTitleWord = titleWords.some(word => 
          topicLower.includes(word) || word.includes(topicLower)
        );

        return hasRelevantTech || hasRelevantTitleWord;
      });

      // Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø¬Ù…ÙˆØ¹ Ø³Ø§Ù„â€ŒÙ‡Ø§ÛŒ ØªØ¬Ø±Ø¨Ù‡ Ù…Ø±ØªØ¨Ø·
      relevantExperience.forEach(exp => {
        const dates = exp.duration.split(/[â€“-]/).map(d => d.trim());
        if (dates.length === 2) {
          // Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø³Ø§Ù„ Ø§Ø² ØªØ§Ø±ÛŒØ®
          const startYear = parseInt(dates[0].split(/[/.]/)[1]);
          let endYear;
          
          if (dates[1].toLowerCase() === 'current') {
            endYear = new Date().getFullYear();
          } else {
            endYear = parseInt(dates[1].split(/[/.]/)[1]);
          }

          // Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø³Ø§Ù„â€ŒÙ‡Ø§
          if (!isNaN(startYear) && !isNaN(endYear)) {
            const years = endYear - startYear;
            // Ø§Ú¯Ø± Ø¯Ø± Ù‡Ù…Ø§Ù† Ø³Ø§Ù„ Ø´Ø±ÙˆØ¹ Ùˆ Ù¾Ø§ÛŒØ§Ù† Ø¯Ø§Ø´ØªÙ‡ØŒ Ù†ÛŒÙ… Ø³Ø§Ù„ Ø­Ø³Ø§Ø¨ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
            if (years === 0) {
              totalYears += 0.5;
            } else {
              totalYears += years;
            }
          }
        }
      });
      
      return Math.round(totalYears);
    };

    // Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² ØªØ¬Ø±Ø¨Ù‡ (35 Ø§Ù…ØªÛŒØ§Ø²)
    const experienceYears = calculateExperienceYears(features.experience);
    console.log("Calculated relevant experience years:", experienceYears);

    // ÙØ±Ù…ÙˆÙ„ Ø§Ù…ØªÛŒØ§Ø²Ø¯Ù‡ÛŒ ØªØ¬Ø±Ø¨Ù‡
    if (experienceYears >= 15) {
      scoreBreakdown.experience = 35;
    } else if (experienceYears >= 10) {
      scoreBreakdown.experience = 28;
    } else if (experienceYears >= 8) {
      scoreBreakdown.experience = 20;
    } else if (experienceYears >= 5) {
      scoreBreakdown.experience = 16;
    } else if (experienceYears >= 3) {
      scoreBreakdown.experience = 8;
    } else {
      scoreBreakdown.experience = 3;
    }

    // ØªØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ø§Ø±ØªØ¨Ø§Ø· Ù…Ù‡Ø§Ø±Øª Ø¨Ø§ topic
    const isSkillRelevant = (skill) => {
      const skillLower = skill.toLowerCase();
      const topicLower = topic.toLowerCase();
      
      // Ø¨Ø±Ø±Ø³ÛŒ Ø§Ø±ØªØ¨Ø§Ø· Ù…Ø³ØªÙ‚ÛŒÙ…
      if (skillLower.includes(topicLower) || topicLower.includes(skillLower)) {
        return true;
      }

      // Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù„Ù…Ø§Øª Ù…Ø´Ø§Ø¨Ù‡
      const skillWords = skillLower.split(/\s+/);
      const topicWords = topicLower.split(/\s+/);
      
      // Ø¨Ø±Ø±Ø³ÛŒ Ø§Ø±ØªØ¨Ø§Ø· Ú©Ù„Ù…Ø§Øª
      const hasRelevantWord = skillWords.some(word => 
        topicWords.some(topicWord => 
          word.includes(topicWord) || topicWord.includes(word)
        )
      );

      // Ø¨Ø±Ø±Ø³ÛŒ Ø§Ø±ØªØ¨Ø§Ø· Ø¯Ø± Ø¹Ø¨Ø§Ø±Ø§Øª Ú†Ù†Ø¯ Ú©Ù„Ù…Ù‡â€ŒØ§ÛŒ
      const hasRelevantPhrase = skillLower.split(/[()]/).some(phrase => 
        phrase.trim().toLowerCase().includes(topicLower) || 
        topicLower.includes(phrase.trim().toLowerCase())
      );

      return hasRelevantWord || hasRelevantPhrase;
    };

    // Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ù…Ù‡Ø§Ø±Øªâ€ŒÙ‡Ø§ (30 Ø§Ù…ØªÛŒØ§Ø²)
    const relevantSkills = features.skills.filter(isSkillRelevant);
    console.log("Relevant skills:", relevantSkills);
    scoreBreakdown.skills = Math.min(relevantSkills.length * 6, 30);

    // ØªØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ø§Ø±ØªØ¨Ø§Ø· Ù¾Ø±ÙˆÚ˜Ù‡ Ø¨Ø§ topic
    const isProjectRelevant = (exp) => {
      const titleLower = exp.title.toLowerCase();
      const technologiesLower = exp.technologies.map(tech => tech.toLowerCase());
      const topicLower = topic.toLowerCase();

      // Ø¨Ø±Ø±Ø³ÛŒ Ø¹Ù†ÙˆØ§Ù† Ø´ØºÙ„
      if (titleLower.includes(topicLower) || topicLower.includes(titleLower)) {
        return true;
      }

      // Ø¨Ø±Ø±Ø³ÛŒ ØªÚ©Ù†ÙˆÙ„ÙˆÚ˜ÛŒâ€ŒÙ‡Ø§
      const hasRelevantTech = technologiesLower.some(tech => 
        tech.includes(topicLower) || topicLower.includes(tech)
      );

      // Ø¨Ø±Ø±Ø³ÛŒ Ø§Ø±ØªØ¨Ø§Ø· Ø¯Ø± Ø¹Ù†ÙˆØ§Ù† Ø´ØºÙ„
      const titleWords = titleLower.split(/\s+/);
      const hasRelevantTitleWord = titleWords.some(word => 
        topicLower.includes(word) || word.includes(topicLower)
      );

      return hasRelevantTech || hasRelevantTitleWord;
    };

    // Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ù¾Ø±ÙˆÚ˜Ù‡â€ŒÙ‡Ø§ (25 Ø§Ù…ØªÛŒØ§Ø²)
    const relevantProjects = features.experience.filter(isProjectRelevant);
    console.log("Relevant projects:", relevantProjects);
    scoreBreakdown.projects = Math.min(relevantProjects.length * 5, 25);

    // Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ù¾ÛŒÚ†ÛŒØ¯Ú¯ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡â€ŒÙ‡Ø§ (10 Ø§Ù…ØªÛŒØ§Ø²)
    const complexProjects = features.experience.filter(exp => {
      const titleLower = exp.title.toLowerCase();
      
      // Ø¨Ø±Ø±Ø³ÛŒ Ø¹Ù†ÙˆØ§Ù†â€ŒÙ‡Ø§ÛŒ Ù…Ø¯ÛŒØ±ÛŒØªÛŒ Ùˆ Ø§Ø±Ø´Ø¯
      const isManagementTitle = 
        titleLower.includes('senior') || 
        titleLower.includes('lead') ||
        titleLower.includes('architect') ||
        titleLower.includes('manager') ||
        titleLower.includes('supervisor') ||
        titleLower.includes('director') ||
        titleLower.includes('head') ||
        titleLower.includes('chief');

      // Ø¨Ø±Ø±Ø³ÛŒ ØªØ¹Ø¯Ø§Ø¯ ØªÚ©Ù†ÙˆÙ„ÙˆÚ˜ÛŒâ€ŒÙ‡Ø§
      const hasManyTechnologies = exp.technologies.length >= 5;

      // Ø¨Ø±Ø±Ø³ÛŒ Ù¾ÛŒÚ†ÛŒØ¯Ú¯ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ¹Ø¯Ø§Ø¯ Ù…Ù‡Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø·
      const relevantSkillsCount = exp.technologies.filter(tech => 
        features.skills.some(skill => 
          skill.toLowerCase().includes(tech.toLowerCase()) || 
          tech.toLowerCase().includes(skill.toLowerCase())
        )
      ).length;

      const hasComplexSkills = relevantSkillsCount >= 3;

      return isManagementTitle || hasManyTechnologies || hasComplexSkills;
    });

    console.log("Complex projects:", complexProjects);
    scoreBreakdown.complexity = Math.min(complexProjects.length * 4, 10);

    // Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ù†Ù‡Ø§ÛŒÛŒ
    totalScore = Object.values(scoreBreakdown).reduce((a, b) => a + b, 0);

    // ØªØ¹ÛŒÛŒÙ† Ø³Ø·Ø­
    let level;
    if (totalScore >= 71) {
      level = "Senior";
    } else if (totalScore >= 41) {
      level = "Mid-level";
    } else {
      level = "Junior";
    }

    res.json({
      success: true,
      score: totalScore,
      level,
      details: {
        experienceYears,
        relevantSkills,
        relevantProjects: relevantProjects.length,
        complexProjects: complexProjects.length
      }
    });

  } catch (error) {
    console.error("Error calculating resume score:", error);
    res.status(500).json({ 
      success: false, 
      message: "Error calculating resume score" 
    });
  }
});

// Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆÙ‚Øª Ø¯Ø± Ù‡Ù†Ú¯Ø§Ù… Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø³Ø±ÙˆØ±
const cleanupTempFiles = () => {
  const tempDir = path.join(__dirname, 'temp');
  if (fs.existsSync(tempDir)) {
    fs.readdir(tempDir, (err, files) => {
      if (err) return;
      for (const file of files) {
        fs.unlink(path.join(tempDir, file), err => {
          if (err) console.error("Error deleting temp file:", err);
        });
      }
    });
  }
};

// Ø§Ø¬Ø±Ø§ÛŒ Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø¯Ø± Ø´Ø±ÙˆØ¹ Ø³Ø±ÙˆØ±
cleanupTempFiles();

// Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø¯ÙˆØ±Ù‡â€ŒØ§ÛŒ Ù‡Ø± 5 Ø¯Ù‚ÛŒÙ‚Ù‡
setInterval(cleanupTempFiles, 5 * 60 * 1000);

// âœ… **Ø§Ø¬Ø±Ø§ÛŒ Ø³Ø±ÙˆØ±**
const PORT = process.env.PORT || 5000;
console.log('ğŸŸ¡ process.env.PORT:', process.env.PORT);
console.log('ğŸŸ¢ Final PORT used by server:', PORT);
app.listen(PORT, () => console.log(`ğŸš€ Server running on port ${PORT}...`));
